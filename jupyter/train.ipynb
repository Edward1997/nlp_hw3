{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\Jhen\n",
      "[nltk_data]     Hao\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "from keras import optimizers\n",
    "import numpy as np\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128  # Batch size for training.\n",
    "epochs = 3  # Number of epochs to train for.\n",
    "latent_dim = 256  # Latent dimensionality of the encoding spac\n",
    "num_samples = 10000  # Number of samples to train on.\n",
    "embedding_dim = 300\n",
    "# Path to the data txt file on disk.\n",
    "data_path = 'data/clean_train.txt'\n",
    "val_data_path = 'data/clean_validation.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the data.\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "val_input_texts = []\n",
    "val_target_texts = []\n",
    "input_characters = set()\n",
    "input_characters.add('<unk>')\n",
    "target_characters = set()\n",
    "target_characters.add('<unk>')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    lines = f.read().split('\\n')\n",
    "with open(val_data_path, 'r', encoding='utf-8') as f:\n",
    "    val_lines = f.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data\n",
    "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
    "    input_text, target_text = line.split('\\t')\n",
    "    # We use \"tab\" as the \"start sequence\" character\n",
    "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
    "    # word base\n",
    "    target_text = word_tokenize(target_text)\n",
    "    target_text.insert(0, '<start>')\n",
    "    target_text.append('<end>')\n",
    "    input_text = word_tokenize(input_text)\n",
    "\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "    for char in input_text:\n",
    "        if char not in input_characters:\n",
    "            input_characters.add(char)\n",
    "    for char in target_text:\n",
    "        if char not in target_characters:\n",
    "            target_characters.add(char)\n",
    "            \n",
    "# validation data\n",
    "for line in val_lines[: min(num_samples, len(val_lines) - 1)]:\n",
    "    val_input_text, val_target_text = line.split('\\t')\n",
    "    # We use \"tab\" as the \"start sequence\" character\n",
    "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
    "    # word_base\n",
    "    val_target_text = word_tokenize(val_target_text)\n",
    "    val_target_text.insert(0, '<start>')\n",
    "    val_target_text.append('<end>')\n",
    "    val_input_text = word_tokenize(val_input_text)\n",
    "\n",
    "    val_input_texts.append(val_input_text)\n",
    "    val_target_texts.append(val_target_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "for t in input_texts:\n",
    "    texts += t\n",
    "freq = nltk.FreqDist(texts)\n",
    "for key, val in freq.items():\n",
    "    if val == 1:\n",
    "        input_characters.remove(key)\n",
    "\n",
    "texts = []\n",
    "for t in target_texts:\n",
    "    texts += t\n",
    "freq = nltk.FreqDist(texts)\n",
    "for key, val in freq.items():\n",
    "    if val == 1:\n",
    "        target_characters.remove(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 10000\n",
      "Number of unique input tokens: 5405\n",
      "Number of unique output tokens: 5398\n",
      "Max sequence length for inputs: 215\n",
      "Max sequence length for outputs: 217\n"
     ]
    }
   ],
   "source": [
    "input_characters = sorted(list(input_characters))\n",
    "target_characters = sorted(list(target_characters))\n",
    "input_characters.insert(0,'<pad>')\n",
    "target_characters.insert(0,'<pad>')\n",
    "num_encoder_tokens = len(input_characters)\n",
    "num_decoder_tokens = len(target_characters)\n",
    "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
    "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
    "\n",
    "print('Number of samples:', len(input_texts))\n",
    "print('Number of unique input tokens:', num_encoder_tokens)\n",
    "print('Number of unique output tokens:', num_decoder_tokens)\n",
    "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
    "print('Max sequence length for outputs:', max_decoder_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_token_index = dict(\n",
    "    [(char, i) for i, char in enumerate(input_characters)])\n",
    "target_token_index = dict(\n",
    "    [(char, i) for i, char in enumerate(target_characters)])\n",
    "\n",
    "encoder_input_data = np.zeros((len(input_texts), max_encoder_seq_length), dtype='int')\n",
    "decoder_input_data = np.zeros((len(input_texts), max_decoder_seq_length), dtype='int')\n",
    "decoder_target_data = np.zeros((len(input_texts), max_decoder_seq_length, 1), dtype='int')\n",
    "\n",
    "val_encoder_input_data = np.zeros((len(val_input_texts), max_encoder_seq_length), dtype='int')\n",
    "val_decoder_input_data = np.zeros((len(val_input_texts), max_decoder_seq_length), dtype='int')\n",
    "val_decoder_target_data = np.zeros((len(val_input_texts), max_decoder_seq_length, 1), dtype='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "    for t, char in enumerate(input_text):\n",
    "        if char in input_token_index:\n",
    "            encoder_input_data[i, t] = input_token_index[char]\n",
    "        else:\n",
    "            encoder_input_data[i, t] = input_token_index['<unk>']\n",
    "\n",
    "    for t, char in enumerate(target_text):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        if char in target_token_index:\n",
    "            index = target_token_index[char]\n",
    "        else:\n",
    "            index = target_token_index['<unk>']\n",
    "        decoder_input_data[i, t] = index\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_target_data[i, t - 1, 0] = index\n",
    "\n",
    "for i, (val_input_text, val_target_text) in enumerate(zip(val_input_texts, val_target_texts)):\n",
    "    for t, char in enumerate(val_input_text):\n",
    "        if t >= max_encoder_seq_length:\n",
    "            break\n",
    "        \n",
    "        if char in input_token_index:\n",
    "            val_encoder_input_data[i, t] = input_token_index[char]\n",
    "        else:\n",
    "            val_encoder_input_data[i, t] = input_token_index['<unk>']\n",
    "\n",
    "    for t, char in enumerate(val_target_text):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        if t >= max_decoder_seq_length:\n",
    "            break\n",
    "        \n",
    "        if char in target_token_index:\n",
    "            index = target_token_index[char]\n",
    "        else:\n",
    "            index = target_token_index['<unk>']\n",
    "        \n",
    "        val_decoder_input_data[i, t] = index\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            val_decoder_target_data[i, t - 1, 0] = index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jhen Hao\\.conda\\envs\\nlp\\lib\\site-packages\\ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\Jhen Hao\\.conda\\envs\\nlp\\lib\\site-packages\\ipykernel_launcher.py:15: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "# embedding layer\n",
    "word2vec_file = \"GoogleNews-vectors-negative300.bin\"\n",
    "word2vec = KeyedVectors.load_word2vec_format(word2vec_file, binary=True)\n",
    "# for encoder\n",
    "embedding_matrix = np.zeros((len(input_characters) + 1, embedding_dim))\n",
    "for i, word in enumerate(input_characters):\n",
    "    if word in word2vec:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = word2vec.wv[word]\n",
    "# for decoder\n",
    "de_embedding_matrix = np.zeros((len(target_characters) + 1, embedding_dim))\n",
    "for i, word in enumerate(target_characters):\n",
    "    if word in word2vec:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        de_embedding_matrix[i] = word2vec.wv[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Jhen Hao\\.conda\\envs\\nlp\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Jhen Hao\\.conda\\envs\\nlp\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Jhen Hao\\.conda\\envs\\nlp\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Jhen Hao\\.conda\\envs\\nlp\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Jhen Hao\\.conda\\envs\\nlp\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Jhen Hao\\.conda\\envs\\nlp\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Jhen Hao\\.conda\\envs\\nlp\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Jhen Hao\\.conda\\envs\\nlp\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Jhen Hao\\.conda\\envs\\nlp\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Jhen Hao\\.conda\\envs\\nlp\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2974: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "encoder_inputs = Input(shape=(None,))\n",
    "embedding_layer = Embedding(len(input_characters) + 1, embedding_dim,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=None,\n",
    "                            trainable=True,\n",
    "                            mask_zero=True)\n",
    "embedding_encoder_inputs = embedding_layer(encoder_inputs)\n",
    "encoder = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(embedding_encoder_inputs)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "de_embedding_layer = Embedding(len(target_characters) + 1, embedding_dim,\n",
    "                            weights=[de_embedding_matrix],\n",
    "                            input_length=None,\n",
    "                            trainable=True,\n",
    "                            mask_zero=True)\n",
    "embedding_decoder_inputs = de_embedding_layer(decoder_inputs)\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(embedding_decoder_inputs,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Jhen Hao\\.conda\\envs\\nlp\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Jhen Hao\\.conda\\envs\\nlp\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3341: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 300)    1621800     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, None, 300)    1619700     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 256), (None, 570368      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, None, 256),  570368      embedding_2[0][0]                \n",
      "                                                                 lstm_1[0][1]                     \n",
      "                                                                 lstm_1[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 5398)   1387286     lstm_2[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 5,769,522\n",
      "Trainable params: 5,769,522\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:From C:\\Users\\Jhen Hao\\.conda\\envs\\nlp\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Jhen Hao\\.conda\\envs\\nlp\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/3\n",
      "10000/10000 [==============================] - 699s 70ms/step - loss: 5.7125 - val_loss: 5.1768\n",
      "Epoch 2/3\n",
      "10000/10000 [==============================] - 819s 82ms/step - loss: 4.9399 - val_loss: 4.5789\n",
      "Epoch 3/3\n",
      "10000/10000 [==============================] - 982s 98ms/step - loss: 4.4580 - val_loss: 4.2788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jhen Hao\\.conda\\envs\\nlp\\lib\\site-packages\\keras\\engine\\network.py:877: UserWarning: Layer lstm_2 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_1/while/Exit_2:0' shape=(?, 256) dtype=float32>, <tf.Tensor 'lstm_1/while/Exit_3:0' shape=(?, 256) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n"
     ]
    }
   ],
   "source": [
    "# Run training\n",
    "# adam = optimizers.Adam(lr=0.001, epsilon=1e-08)\n",
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
    "model.summary()\n",
    "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=([val_encoder_input_data, val_decoder_input_data], val_decoder_target_data))\n",
    "# Save model\n",
    "model.save('s2s.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_weights('s2s.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sampling models\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    embedding_decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1))\n",
    "    # print(states_value.shape)\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0] = target_token_index['<start>']\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = []\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, 0, :])\n",
    "        sampled_char = target_characters[sampled_token_index]\n",
    "        decoded_sentence.append(sampled_char)\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '<end>' or\n",
    "           len(decoded_sentence) >= max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "        else:\n",
    "            # Update the target sequence (of length 1).\n",
    "            target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "            # Update states\n",
    "            states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "Input sentence: ['In', 'my', 'opinion', 'the', 'TV', 'channels', 'should', 'show', 'the', 'violent', 'movies', 'and', 'TV', 'shows', 'in', 'night', ',', 'not', 'in', 'the', 'afternoon', '.']\n",
      "\n",
      "Decoded sentence: ['The', '<unk>', 'is', 'a', '<unk>', 'of', 'the', '<unk>', ',', '<unk>', ',', 'the', '<unk>', ',', '<unk>', ',', 'the', '<unk>', ',', '<unk>', '.', '<end>']\n",
      "---\n",
      "Input sentence: ['There', 'I', 'began', 'to', 'study', 'Family', 'Therapy', ',', 'discipline', 'that', 'I', 'enjoy', 'too', 'much', ',', 'because', 'I', \"'ve\", 'seen', 'I', 'can', 'help', 'people', 'about', 'their', 'troubles', '..']\n",
      "\n",
      "Decoded sentence: ['In', 'the', '<unk>', ',', 'I', 'have', 'a', 'lot', 'of', 'the', '<unk>', 'of', 'the', '<unk>', ',', 'and', 'the', '<unk>', ',', '<unk>', ',', 'the', '<unk>', ',', '<unk>', '.', '<end>']\n",
      "---\n",
      "Input sentence: ['It', 'seems', 'me', ',', 'that', 'in', 'this', 'song', 'there', 'are', 'romantic', 'notes', '.']\n",
      "\n",
      "Decoded sentence: ['The', '<unk>', 'is', 'a', '<unk>', 'of', 'the', '<unk>', 'of', 'the', '<unk>', '.', '<end>']\n",
      "---\n",
      "Input sentence: ['So', ',', 'I', 'want', 'to', 'say', 'that', 'I', 'admire', 'your', 'right', 'disposition', 'and', 'sacrifice', 'in', 'solve', 'the', 'problems', 'related', 'a', 'your', 'phobia', ',', 'as', 'for', 'example', 'going', 'out', 'the', 'company', '.']\n",
      "\n",
      "Decoded sentence: ['The', '<unk>', 'is', 'a', '<unk>', 'of', 'the', '<unk>', ',', 'I', 'have', 'a', 'lot', 'of', 'the', '<unk>', 'of', 'the', '<unk>', ',', 'and', 'the', '<unk>', ',', '<unk>', ',', '<unk>', ',', '<unk>', '.', '<end>']\n",
      "---\n",
      "Input sentence: ['I', 'graduated', 'Chung', 'university', '.']\n",
      "\n",
      "Decoded sentence: ['I', \"'m\", 'to', 'go', 'to', 'music', '.', '<end>']\n"
     ]
    }
   ],
   "source": [
    "for seq_index in range(5):\n",
    "    # Take one sequence (part of the training set)\n",
    "    # for trying out decoding.\n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('---')\n",
    "    print('Input sentence:', input_texts[seq_index])\n",
    "    print('')\n",
    "    print('Decoded sentence:', decoded_sentence)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.input_layer.InputLayer object at 0x000001FD605D6A90>\n",
      "<keras.engine.input_layer.InputLayer object at 0x000001FD605D6EF0>\n",
      "<keras.layers.embeddings.Embedding object at 0x000001FD605D6A58>\n",
      "<keras.layers.embeddings.Embedding object at 0x000001FD6125FA58>\n",
      "<keras.layers.recurrent.LSTM object at 0x000001FD605D6F98>\n",
      "<keras.layers.recurrent.LSTM object at 0x000001FC14F365C0>\n",
      "<keras.layers.core.Dense object at 0x000001FC14FC0CC0>\n",
      "---\n",
      "<keras.engine.input_layer.InputLayer object at 0x000001FD605D6A90>\n",
      "<keras.layers.embeddings.Embedding object at 0x000001FD605D6A58>\n",
      "<keras.layers.recurrent.LSTM object at 0x000001FD605D6F98>\n",
      "---\n",
      "<keras.engine.input_layer.InputLayer object at 0x000001FD605D6EF0>\n",
      "<keras.layers.embeddings.Embedding object at 0x000001FD6125FA58>\n",
      "<keras.engine.input_layer.InputLayer object at 0x000001FC184319E8>\n",
      "<keras.engine.input_layer.InputLayer object at 0x000001FC184318D0>\n",
      "<keras.layers.recurrent.LSTM object at 0x000001FC14F365C0>\n",
      "<keras.layers.core.Dense object at 0x000001FC14FC0CC0>\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer)\n",
    "print('---')\n",
    "for layer in encoder_model.layers:\n",
    "    print(layer)\n",
    "print('---')\n",
    "for layer in decoder_model.layers:\n",
    "    print(layer)\n",
    "print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here\n",
      "in\n",
      "Brazil\n",
      "it\n",
      "is\n",
      "very\n",
      "common\n",
      "we\n",
      "have\n",
      "problems\n",
      "with\n",
      "family\n",
      "business\n",
      ".\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n"
     ]
    }
   ],
   "source": [
    "# print(input_token_index)\n",
    "# print(input_characters)\n",
    "for data in encoder_input_data[10]:\n",
    "    print(input_characters[data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
